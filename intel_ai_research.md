# Intel AI relative project index

* https://github.com/NervanaSystems/coach - Reinforcement Learning Coach by Intel AI Lab enables easy experimentation with state of the art Reinforcement Learning algorithms https://nervanasystems.github.io/coach/
* https://github.com/icnc/icnc - Intel(R) Concurrent Collections for C++. The CnC homepage is here: https://icnc.github.io
* https://github.com/NervanaSystems/distiller - Neural Network Distiller by Intel AI Lab: a Python package for neural network compression research. https://nervanasystems.github.io/distiller
* https://github.com/intel/clDNN - Compute Library for Deep Neural Networks (clDNN) is an open source performance library for Deep Learning (DL) applications intended for acceleration of DL Inference on Intel® Processor Graphics – including HD Graphics and Iris® Graphics.
clDNN includes highly optimized building blocks for implementation of convolutional neural networks (CNN) with C and C++ interfaces. We created this project to enable the DL community to innovate on Intel® processors.
* https://github.com/opencv/dldt/tree/2019/inference-engine/thirdparty/clDNN - Compute Library for Deep Neural Networks (clDNN) is an open source performance library for Deep Learning (DL) applications intended for acceleration of DL Inference on Intel® Processor Graphics – including HD Graphics and Iris® Graphics. clDNN includes highly optimized building blocks for implementation of convolutional neural networks (CNN) with C and C++ interfaces. We created this project to enable the DL community to innovate on Intel® processors.
* https://github.com/IntelPython/sdc - Intel® Scalable Dataframe Compiler for Pandas* https://intelpython.github.io/sdc-doc/
* https://github.com/IntelAI/models - This repository contains links to pre-trained models, sample scripts, best practices, and step-by-step tutorials for many popular open-source machine learning models optimized by Intel to run on Intel® Xeon® Scalable processors.
* https://github.com/mstfldmr/IntelAIWorkshop - Presentations and sample notebooks for Intel AI Workshop, prepared and delivered by Mustafa Aldemir, 2017-2018
* https://github.com/mstfldmr/Intel-IoT-Workshop - This repository contains the documentation and materials of IoT workshops held by Intel Turkey, within the IoT Catal-IST Program. Each workshop covers a different subset of the content below, and each chapter's materials are collected in a separate folder. Please ask your Intel contact which chapters will be covered.
* https://github.com/NervanaSystems/neon - neon is Intel's reference deep learning framework committed to best performance on all hardware. Designed for ease-of-use and extensibility. Intel® Nervana™ reference deep learning framework committed to best performance on all hardware http://neon.nervanasys.com/docs/latest. This project will no longer be maintained by Intel. Intel will not provide or guarantee development of or support for this project, including but not limited to, maintenance, bug fixes, new releases or updates.
* https://github.com/intel/daal - Intel(R) oneAPI Data Analytics Library (oneDAL) is a library that helps speed up big data analysis by providing highly optimized algorithmic building blocks for all stages of data analytics (preprocessing, transformation, analysis, modeling, validation, and decision making) in batch, online, and distributed processing modes of computation. The current version of oneDAL provides Data Parallel C++ (DPC++) API extensions to the traditional C++ interface.
* https://github.com/intel/Detectron - FAIR's research platform for object detection research, implementing popular algorithms like Mask R-CNN and RetinaNet. Detectron is Facebook AI Research's software system that implements state-of-the-art object detection algorithms, including Mask R-CNN. It is written in Python and powered by the Caffe2 deep learning framework.
* https://github.com/intel/oim - Open Infrastructure Manager (OIM) is an open source project which simplifies the integration of storage and network acceleration into cloud environments like Kubernetes, Mesos and OpenStack.
* https://github.com/intel/robot_devkit_doc - 
* https://github.com/intel/Intel-AI-Skills - Sample applications to show API usage for Intel(R) AI Skills released on nuget.org.
* https://github.com/intel/openlldp - Link Layer Discovery Protocol (LLDP) Agent with Data Center Bridging (DCB) for Intel(R) Network Connections.
* https://github.com/intel/beignet - Beignet is an open source implementation of the OpenCL specification - a generic compute oriented API. Here is Beignet Source Code Mirror in github- This is a publish-only repository and all pull requests are ignored. Please follow https://wiki.freedesktop.org/www/Software/Beignet/ for any of your improvements. 
* https://github.com/intel/telemetry-aware-scheduling - Telemetry Aware Scheduling (TAS) makes telemetry data available to scheduling and descheduling decisions in Kubernetes. Through a user defined policy, TAS enables rule based decisions on pod placement powered by up to date platform metrics. Policies can be applied on a workload by workload basis - allowing the right indicators to be used to place the right pod. This software is a pre-production alpha version and should not be deployed to production servers.
* https://github.com/intel/mkl-dnn - Deep Neural Network Library (DNNL) https://01.org/dnnl Deep Neural Network Library (DNNL) is an open-source performance library for deep learning applications. The library includes basic building blocks for neural networks optimized for Intel Architecture Processors and Intel Processor Graphics.
* https://github.com/intel/MLSL - Intel(R) Machine Learning Scaling Library is a library providing an efficient implementation of communication patterns used in deep learning.



# others
* https://github.com/intel-go/cpuid - Intel CPUID library for Go Programming Language
* https://github.com/platomav/CPUMicrocodes - Intel, AMD, VIA & Freescale CPU Microcode Repositories
* https://github.com/intel/IntelSEAPI - Intel® SEAPI is the translator of itt_notify calls into several OS specific and third party tracing formats. You can use it as memory/performance/whatever profiler.
* https://github.com/intelpt/WindowsIntelPT - This driver implements the Intel Processor Trace functionality in Intel Skylake architecture for Microsoft Windows.
* https://github.com/intel/tbb - Official Threading Building Blocks (TBB) GitHub repository. For Commercial Intel® TBB distribution, please click here: https://software.intel.com/en-us/tbb
https://github.com/intel/llvm - Intel staging area for llvm.org contribution. Home for Intel LLVM-based projects.
* https://github.com/LordNoteworthy/cpu-internals - CPU Internals
These notes are taken from Intel SDM. You can consider them as a short/resumed version of some parts of the manuals that I found worth looking at when learning about system programming, OS internals or virtualization.
* https://github.com/Intel-Media-SDK/MediaSDK - Intel® Media SDK
Intel® Media SDK provides a plain C API to access hardware-accelerated video decode, encode and filtering on Intel® Gen graphics hardware platforms. Implementation written in C++ 11 with parts in C-for-Media (CM).
* https://github.com/IntelRealSense/librealsense - Intel® RealSense™ SDK 2.0 is a cross-platform library for Intel® RealSense™ depth cameras (D400 series and the SR300) and the T265 tracking camera.
* https://github.com/intel/libipt - libipt - an Intel(R) Processor Trace decoder library. 
* https://github.com/intel/libyami - Yet Another Media Infrastructure. It is YUMMY to your video experience on Linux like platform. Yami is core building block for media solution. it parses video stream and decodes them leverage hardware acceleration.
* https://github.com/intel/rapid-design-methods-for-developing-hardware-accelerators - rapid design methods for developing hardware accelerators. Googletest changed its library name in recent versions. Our latest code will not link to older versions. Please update googletest if you have link errors. (Feb. 6, 2019) Linking changed again for googletest (Oct. 16, 2019). 
* https://github.com/intel/video-analytics-serving - Video Analytics Serving is designed to simplify the deployment and use of hardware optimized video analytics pipelines. It offers developers a simple way to create REStful APIs to start, stop, enumerate and customize pre-defined pipelines using either GStreamer or FFmpeg. Developers create pipeline templates using their framework of choice and Video Analytics Serving manages launching pipeline instances based on incoming requests.

# references
* https://github.com/opencv
* https://github.com/IntelPython
* https://github.com/intel-go
* https://github.com/IntelAI
